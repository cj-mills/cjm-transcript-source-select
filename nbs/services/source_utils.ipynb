{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "su-title",
   "metadata": {},
   "source": [
    "# source_utils\n",
    "\n",
    "> Source record operations for metadata extraction, grouping, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-default-exp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp services.source_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-imports",
   "metadata": {},
   "outputs": [],
   "source": "#| export\nfrom typing import Any, List, Dict, Optional, Set\nfrom pathlib import Path\nimport json"
  },
  {
   "cell_type": "markdown",
   "id": "su-metadata-hdr",
   "metadata": {},
   "source": [
    "## Metadata Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-extract-batch-id",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_batch_id(\n",
    "    metadata: Any  # Metadata dict or JSON string\n",
    ") -> str:  # Batch ID or \"No Batch ID\"\n",
    "    \"\"\"Extract batch_id from transcription metadata.\"\"\"\n",
    "    if not metadata:\n",
    "        return \"No Batch ID\"\n",
    "    \n",
    "    # Parse JSON string if needed\n",
    "    if isinstance(metadata, str):\n",
    "        try:\n",
    "            metadata = json.loads(metadata)\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            return \"No Batch ID\"\n",
    "    \n",
    "    batch_id = metadata.get(\"batch_id\", \"\")\n",
    "    return batch_id if batch_id else \"No Batch ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-extract-model-name",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_model_name(\n",
    "    metadata: Any  # Metadata dict or JSON string\n",
    ") -> str:  # Formatted model name for display\n",
    "    \"\"\"Extract and format model name from transcription metadata.\"\"\"\n",
    "    if not metadata:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Parse JSON string if needed\n",
    "    if isinstance(metadata, str):\n",
    "        try:\n",
    "            metadata = json.loads(metadata)\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            return \"Unknown\"\n",
    "    \n",
    "    model = metadata.get(\"model\", \"\")\n",
    "    if not model:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Extract just the model name (after the slash if present)\n",
    "    # e.g., \"mistralai/Voxtral-Mini-3B-2507\" -> \"Voxtral-Mini-3B-2507\"\n",
    "    if \"/\" in model:\n",
    "        model = model.split(\"/\")[-1]\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "su-grouping-hdr",
   "metadata": {},
   "source": [
    "## Record Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-group-transcriptions",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def group_transcriptions(\n",
    "    transcriptions: List[Dict[str, Any]],  # List of transcription records\n",
    "    group_by: str = \"media_path\"  # Grouping mode: \"media_path\" or \"batch_id\"\n",
    ") -> Dict[str, List[Dict[str, Any]]]:  # Grouped transcriptions\n",
    "    \"\"\"Group transcription records by the specified field.\"\"\"\n",
    "    groups = {}\n",
    "    for t in transcriptions:\n",
    "        if group_by == \"batch_id\":\n",
    "            key = extract_batch_id(t.get(\"metadata\"))\n",
    "        else:\n",
    "            # Default to media_path grouping\n",
    "            key = t.get(\"media_path\", \"Unknown\")\n",
    "        \n",
    "        if key not in groups:\n",
    "            groups[key] = []\n",
    "        groups[key].append(t)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-group-by-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def group_transcriptions_by_audio(\n",
    "    transcriptions: List[Dict[str, Any]]  # List of transcription records\n",
    ") -> Dict[str, List[Dict[str, Any]]]:  # Grouped by media_path\n",
    "    \"\"\"Group transcription records by their source audio file.\"\"\"\n",
    "    return group_transcriptions(transcriptions, group_by=\"media_path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "su-selection-hdr",
   "metadata": {},
   "source": [
    "## Selection Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-is-source-selected",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef is_source_selected(\n    record_id: str,  # Job ID to check\n    provider_id: str,  # Provider ID to check\n    selected_sources: List[Dict[str, str]]  # List of selected sources\n) -> bool:  # True if source is selected\n    \"\"\"Check if a source is in the selected list by (record_id, provider_id) pair.\"\"\"\n    return any(\n        s.get(\"record_id\") == record_id and s.get(\"provider_id\") == provider_id\n        for s in selected_sources\n    )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yt3azuiiy3g",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef get_selected_media_paths(\n    selected_sources: List[Dict[str, str]],  # Current selections (record_id, provider_id)\n    all_transcriptions: List[Dict[str, Any]],  # All available transcription records\n) -> Set[str]:  # Media paths already represented in selections\n    \"\"\"Get the set of media_paths for currently selected sources.\"\"\"\n    selected_keys = {(s.get(\"record_id\"), s.get(\"provider_id\")) for s in selected_sources}\n    return {\n        t.get(\"media_path\") for t in all_transcriptions\n        if (t.get(\"record_id\"), t.get(\"provider_id\")) in selected_keys\n        and t.get(\"media_path\")\n    }"
  },
  {
   "cell_type": "markdown",
   "id": "vk1b3dqivme",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tg25xqgkaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def filter_transcriptions(\n",
    "    transcriptions: List[Dict[str, Any]],  # List of transcription records to filter\n",
    "    search_text: str,  # Search term for case-insensitive substring matching\n",
    ") -> List[Dict[str, Any]]:  # Filtered transcription records\n",
    "    \"\"\"Filter transcriptions by substring match across record_id, media_path, and text fields.\"\"\"\n",
    "    if not search_text or not search_text.strip():\n",
    "        return transcriptions\n",
    "    \n",
    "    search_lower = search_text.lower().strip()\n",
    "    return [\n",
    "        t for t in transcriptions\n",
    "        if (search_lower in t.get(\"record_id\", \"\").lower() or\n",
    "            search_lower in t.get(\"media_path\", \"\").lower() or\n",
    "            search_lower in t.get(\"text\", \"\").lower())\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcm2e71wnt7",
   "metadata": {},
   "source": [
    "## Group Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u78r83i7z6i",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef select_all_in_group(\n    transcriptions: List[Dict[str, Any]],  # All transcription records\n    group_key: str,  # Group key to match against\n    grouping_mode: str,  # Grouping mode: \"media_path\" or \"batch_id\"\n    selected_sources: List[Dict[str, str]],  # Current selections\n    excluded_media_paths: Optional[Set[str]] = None,  # Media paths to skip (already selected)\n) -> List[Dict[str, str]]:  # Updated selections with new items appended\n    \"\"\"Add all transcriptions matching a group key to the selection list, skipping duplicates.\"\"\"\n    # Filter transcriptions by group key\n    if grouping_mode == \"batch_id\":\n        matching = [t for t in transcriptions if extract_batch_id(t.get(\"metadata\")) == group_key]\n    else:\n        matching = [t for t in transcriptions if t.get(\"media_path\") == group_key]\n    \n    # Deduplicate against existing selections using (record_id, provider_id) pairs\n    existing_keys = {(s.get(\"record_id\"), s.get(\"provider_id\")) for s in selected_sources}\n    used_paths = set(excluded_media_paths) if excluded_media_paths else set()\n    result = list(selected_sources)\n    for t in matching:\n        record_id = t.get(\"record_id\")\n        provider_id = t.get(\"provider_id\", \"\")\n        media_path = t.get(\"media_path\")\n        key = (record_id, provider_id)\n        if not record_id or key in existing_keys:\n            continue\n        # Skip if media_path already represented\n        if excluded_media_paths is not None and media_path and media_path in used_paths:\n            continue\n        result.append({\"record_id\": record_id, \"provider_id\": provider_id})\n        existing_keys.add(key)\n        if media_path:\n            used_paths.add(media_path)\n    \n    return result"
  },
  {
   "cell_type": "markdown",
   "id": "hvnyunil5ca",
   "metadata": {},
   "source": [
    "## Selection Mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gtja2coiu2n",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef toggle_source_selection(\n    record_id: str,  # Job ID to toggle\n    provider_id: str,  # Plugin name for the source\n    selected_sources: List[Dict[str, str]],  # Current selections\n) -> List[Dict[str, str]]:  # Updated selections\n    \"\"\"Toggle a source in or out of the selection list by (record_id, provider_id) pair.\"\"\"\n    if any(s.get(\"record_id\") == record_id and s.get(\"provider_id\") == provider_id\n           for s in selected_sources):\n        return [s for s in selected_sources\n                if not (s.get(\"record_id\") == record_id and s.get(\"provider_id\") == provider_id)]\n    else:\n        return selected_sources + [{\"record_id\": record_id, \"provider_id\": provider_id}]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gvvdhrgpf6l",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def reorder_item(\n",
    "    selected_sources: List[Dict[str, str]],  # Current selections\n",
    "    record_id: str,  # Record ID of item to move\n",
    "    provider_id: str,  # Provider ID of item to move\n",
    "    direction: str,  # Direction: \"up\" or \"down\"\n",
    ") -> List[Dict[str, str]]:  # Reordered selections\n",
    "    \"\"\"Move an item up or down in the selection list by swapping with its neighbor.\"\"\"\n",
    "    sources = list(selected_sources)\n",
    "    current_index = next(\n",
    "        (i for i, s in enumerate(sources)\n",
    "         if s.get(\"record_id\") == record_id and s.get(\"provider_id\") == provider_id),\n",
    "        None\n",
    "    )\n",
    "    \n",
    "    if current_index is None:\n",
    "        return sources\n",
    "    \n",
    "    if direction == \"up\" and current_index > 0:\n",
    "        sources[current_index], sources[current_index - 1] = sources[current_index - 1], sources[current_index]\n",
    "    elif direction == \"down\" and current_index < len(sources) - 1:\n",
    "        sources[current_index], sources[current_index + 1] = sources[current_index + 1], sources[current_index]\n",
    "    \n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aes4jtpch1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def reorder_sources(\n",
    "    selected_sources: List[Dict[str, str]],  # Current selections\n",
    "    new_order_ids: List[str],  # Job IDs in desired order\n",
    ") -> List[Dict[str, str]]:  # Reordered selections\n",
    "    \"\"\"Reorder sources to match the given job ID order.\"\"\"\n",
    "    if not new_order_ids:\n",
    "        return list(selected_sources)\n",
    "    \n",
    "    source_lookup = {s.get(\"record_id\"): s for s in selected_sources}\n",
    "    reordered = [source_lookup[jid] for jid in new_order_ids if jid in source_lookup]\n",
    "    \n",
    "    # Append any sources not in the new order (safety fallback)\n",
    "    new_order_set = set(new_order_ids)\n",
    "    for s in selected_sources:\n",
    "        if s.get(\"record_id\") not in new_order_set:\n",
    "            reordered.append(s)\n",
    "    \n",
    "    return reordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c893cekhe4h",
   "metadata": {},
   "source": [
    "## Tab Navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4tcys7w8j16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_next_tab(\n",
    "    direction: str,  # Direction: \"prev\", \"next\", or a direct tab name\n",
    "    current_tab: str,  # Currently active tab name\n",
    "    tabs: List[str],  # Available tab names in order\n",
    ") -> str:  # New active tab name\n",
    "    \"\"\"Calculate the next tab based on direction or direct selection.\"\"\"\n",
    "    if direction in tabs:\n",
    "        return direction\n",
    "    \n",
    "    current_idx = tabs.index(current_tab) if current_tab in tabs else 0\n",
    "    if direction == \"prev\":\n",
    "        return tabs[(current_idx - 1) % len(tabs)]\n",
    "    else:\n",
    "        return tabs[(current_idx + 1) % len(tabs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "su-filesystem-hdr",
   "metadata": {},
   "source": [
    "## Filesystem Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-check-audio-exists",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_audio_exists(\n",
    "    media_path: str  # Path to audio file\n",
    ") -> bool:  # True if file exists\n",
    "    \"\"\"Check if the audio file exists at the given path.\"\"\"\n",
    "    if not media_path or media_path == \"Unknown\":\n",
    "        return False\n",
    "    return Path(media_path).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-validate-browse-path",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_browse_path(\n",
    "    path: str  # Path to validate\n",
    ") -> str:  # Validated and resolved path, or home directory on error\n",
    "    \"\"\"Validate a browse path for security. Returns home directory on invalid input.\"\"\"\n",
    "    try:\n",
    "        resolved = Path(path).resolve()\n",
    "        if resolved.exists() and resolved.is_dir():\n",
    "            return str(resolved)\n",
    "    except (ValueError, OSError):\n",
    "        pass\n",
    "    return str(Path.home())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "su-tests-hdr",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-test-batch-id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_batch_id tests passed\n"
     ]
    }
   ],
   "source": [
    "assert extract_batch_id(None) == \"No Batch ID\"\n",
    "assert extract_batch_id({\"batch_id\": \"batch_123\"}) == \"batch_123\"\n",
    "assert extract_batch_id('{\"batch_id\": \"batch_456\"}') == \"batch_456\"\n",
    "assert extract_batch_id({}) == \"No Batch ID\"\n",
    "print(\"extract_batch_id tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-test-model-name",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_model_name tests passed\n"
     ]
    }
   ],
   "source": [
    "assert extract_model_name(None) == \"Unknown\"\n",
    "assert extract_model_name({\"model\": \"mistralai/Voxtral-Mini-3B\"}) == \"Voxtral-Mini-3B\"\n",
    "assert extract_model_name({\"model\": \"whisper-large\"}) == \"whisper-large\"\n",
    "assert extract_model_name({}) == \"Unknown\"\n",
    "print(\"extract_model_name tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-test-grouping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_transcriptions tests passed\n"
     ]
    }
   ],
   "source": [
    "records = [\n",
    "    {\"record_id\": \"1\", \"media_path\": \"a.wav\"},\n",
    "    {\"record_id\": \"2\", \"media_path\": \"a.wav\"},\n",
    "    {\"record_id\": \"3\", \"media_path\": \"b.wav\"},\n",
    "]\n",
    "groups = group_transcriptions(records)\n",
    "assert len(groups) == 2\n",
    "assert len(groups[\"a.wav\"]) == 2\n",
    "assert len(groups[\"b.wav\"]) == 1\n",
    "print(\"group_transcriptions tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-test-selection",
   "metadata": {},
   "outputs": [],
   "source": "sources = [{\"record_id\": \"a\", \"provider_id\": \"p1\"}, {\"record_id\": \"b\", \"provider_id\": \"p2\"}]\nassert is_source_selected(\"a\", \"p1\", sources) == True\nassert is_source_selected(\"a\", \"p2\", sources) == False  # Same record_id, different provider\nassert is_source_selected(\"c\", \"p1\", sources) == False\nprint(\"is_source_selected tests passed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45mj7fm9nuv",
   "metadata": {},
   "outputs": [],
   "source": "all_t = [\n    {\"record_id\": \"j1\", \"provider_id\": \"p1\", \"media_path\": \"a.wav\"},\n    {\"record_id\": \"j2\", \"provider_id\": \"p1\", \"media_path\": \"b.wav\"},\n    {\"record_id\": \"j3\", \"provider_id\": \"p2\", \"media_path\": \"c.wav\"},\n]\nselected = [{\"record_id\": \"j1\", \"provider_id\": \"p1\"}, {\"record_id\": \"j3\", \"provider_id\": \"p2\"}]\npaths = get_selected_media_paths(selected, all_t)\nassert paths == {\"a.wav\", \"c.wav\"}\n\n# Empty selections\nassert get_selected_media_paths([], all_t) == set()\n\n# Selection not in transcriptions (stale reference)\nassert get_selected_media_paths([{\"record_id\": \"jX\", \"provider_id\": \"pX\"}], all_t) == set()\n\nprint(\"get_selected_media_paths tests passed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4zgxpsoqb9h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_transcriptions tests passed\n"
     ]
    }
   ],
   "source": [
    "records = [\n",
    "    {\"record_id\": \"job_001\", \"media_path\": \"/data/podcast.wav\", \"text\": \"Hello world\"},\n",
    "    {\"record_id\": \"job_002\", \"media_path\": \"/data/lecture.wav\", \"text\": \"Machine learning intro\"},\n",
    "    {\"record_id\": \"job_003\", \"media_path\": \"/data/podcast.wav\", \"text\": \"Goodbye world\"},\n",
    "]\n",
    "assert len(filter_transcriptions(records, \"\")) == 3\n",
    "assert len(filter_transcriptions(records, \"  \")) == 3\n",
    "assert len(filter_transcriptions(records, \"podcast\")) == 2\n",
    "assert len(filter_transcriptions(records, \"PODCAST\")) == 2\n",
    "assert len(filter_transcriptions(records, \"machine\")) == 1\n",
    "assert len(filter_transcriptions(records, \"job_001\")) == 1\n",
    "assert len(filter_transcriptions(records, \"nonexistent\")) == 0\n",
    "print(\"filter_transcriptions tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kmujvilq62l",
   "metadata": {},
   "outputs": [],
   "source": "transcriptions = [\n    {\"record_id\": \"j1\", \"provider_id\": \"p1\", \"media_path\": \"a.wav\", \"metadata\": '{\"batch_id\": \"b1\"}'},\n    {\"record_id\": \"j2\", \"provider_id\": \"p1\", \"media_path\": \"a.wav\", \"metadata\": '{\"batch_id\": \"b1\"}'},\n    {\"record_id\": \"j3\", \"provider_id\": \"p2\", \"media_path\": \"b.wav\", \"metadata\": '{\"batch_id\": \"b2\"}'},\n]\n\n# Select all by media_path (no exclusion)\nresult = select_all_in_group(transcriptions, \"a.wav\", \"media_path\", [])\nassert len(result) == 2\nassert result[0][\"record_id\"] == \"j1\"\nassert result[1][\"record_id\"] == \"j2\"\n\n# Select all by batch_id\nresult = select_all_in_group(transcriptions, \"b1\", \"batch_id\", [])\nassert len(result) == 2\n\n# Deduplication: j1/p1 already selected\nresult = select_all_in_group(transcriptions, \"a.wav\", \"media_path\", [{\"record_id\": \"j1\", \"provider_id\": \"p1\"}])\nassert len(result) == 2\nassert result[0][\"record_id\"] == \"j1\"\nassert result[1][\"record_id\"] == \"j2\"\n\n# Same record_id from different provider is NOT a duplicate\nresult = select_all_in_group(transcriptions, \"a.wav\", \"media_path\", [{\"record_id\": \"j1\", \"provider_id\": \"p_other\"}])\nassert len(result) == 3  # existing + j1/p1 + j2/p1\n\n# No matches\nresult = select_all_in_group(transcriptions, \"nonexistent.wav\", \"media_path\", [])\nassert len(result) == 0\n\n# With excluded_media_paths: skip sources whose audio is already represented\nresult = select_all_in_group(transcriptions, \"a.wav\", \"media_path\", [], excluded_media_paths={\"a.wav\"})\nassert len(result) == 0  # All matching records share excluded media_path\n\n# excluded_media_paths with batch_id grouping across different audio files\nmixed = [\n    {\"record_id\": \"j1\", \"provider_id\": \"p1\", \"media_path\": \"a.wav\", \"metadata\": '{\"batch_id\": \"b1\"}'},\n    {\"record_id\": \"j2\", \"provider_id\": \"p1\", \"media_path\": \"b.wav\", \"metadata\": '{\"batch_id\": \"b1\"}'},\n]\nresult = select_all_in_group(mixed, \"b1\", \"batch_id\", [], excluded_media_paths={\"a.wav\"})\nassert len(result) == 1\nassert result[0][\"record_id\"] == \"j2\"  # Only b.wav source added\n\nprint(\"select_all_in_group tests passed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k3hjuzfv3d",
   "metadata": {},
   "outputs": [],
   "source": "# Toggle on: add new source\nsources = [{\"record_id\": \"a\", \"provider_id\": \"p1\"}]\nresult = toggle_source_selection(\"b\", \"p2\", sources)\nassert len(result) == 2\nassert result[1][\"record_id\"] == \"b\"\n\n# Toggle off: remove existing source\nresult = toggle_source_selection(\"a\", \"p1\", sources)\nassert len(result) == 0\n\n# Same record_id but different provider: adds (not toggle off)\nresult = toggle_source_selection(\"a\", \"p2\", sources)\nassert len(result) == 2\n\n# Original list is not mutated\nassert len(sources) == 1\n\nprint(\"toggle_source_selection tests passed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9hh8g4wl1bh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reorder_item tests passed\n"
     ]
    }
   ],
   "source": [
    "sources = [\n",
    "    {\"record_id\": \"a\", \"provider_id\": \"p1\"}, \n",
    "    {\"record_id\": \"b\", \"provider_id\": \"p1\"}, \n",
    "    {\"record_id\": \"c\", \"provider_id\": \"p1\"}\n",
    "]\n",
    "\n",
    "# Move middle item up\n",
    "result = reorder_item(sources, \"b\", \"p1\", \"up\")\n",
    "assert [s[\"record_id\"] for s in result] == [\"b\", \"a\", \"c\"]\n",
    "\n",
    "# Move middle item down\n",
    "result = reorder_item(sources, \"b\", \"p1\", \"down\")\n",
    "assert [s[\"record_id\"] for s in result] == [\"a\", \"c\", \"b\"]\n",
    "\n",
    "# Move first item up (no-op)\n",
    "result = reorder_item(sources, \"a\", \"p1\", \"up\")\n",
    "assert [s[\"record_id\"] for s in result] == [\"a\", \"b\", \"c\"]\n",
    "\n",
    "# Move last item down (no-op)\n",
    "result = reorder_item(sources, \"c\", \"p1\", \"down\")\n",
    "assert [s[\"record_id\"] for s in result] == [\"a\", \"b\", \"c\"]\n",
    "\n",
    "# Item not found (no-op)\n",
    "result = reorder_item(sources, \"x\", \"p1\", \"up\")\n",
    "assert [s[\"record_id\"] for s in result] == [\"a\", \"b\", \"c\"]\n",
    "\n",
    "# Original list is not mutated\n",
    "assert [s[\"record_id\"] for s in sources] == [\"a\", \"b\", \"c\"]\n",
    "\n",
    "print(\"reorder_item tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ldvoe019tr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reorder_sources tests passed\n"
     ]
    }
   ],
   "source": [
    "sources = [{\"record_id\": \"a\"}, {\"record_id\": \"b\"}, {\"record_id\": \"c\"}]\n",
    "\n",
    "# Normal reorder\n",
    "result = reorder_sources(sources, [\"c\", \"a\", \"b\"])\n",
    "assert [s[\"record_id\"] for s in result] == [\"c\", \"a\", \"b\"]\n",
    "\n",
    "# Empty new_order_ids returns copy\n",
    "result = reorder_sources(sources, [])\n",
    "assert [s[\"record_id\"] for s in result] == [\"a\", \"b\", \"c\"]\n",
    "\n",
    "# Unknown IDs in new_order are skipped\n",
    "result = reorder_sources(sources, [\"b\", \"x\", \"a\"])\n",
    "assert [s[\"record_id\"] for s in result] == [\"b\", \"a\", \"c\"]\n",
    "\n",
    "# Missing IDs from new_order are appended\n",
    "result = reorder_sources(sources, [\"c\"])\n",
    "assert [s[\"record_id\"] for s in result] == [\"c\", \"a\", \"b\"]\n",
    "\n",
    "print(\"reorder_sources tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ixs8yuerze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_next_tab tests passed\n"
     ]
    }
   ],
   "source": [
    "tabs = [\"db\", \"files\"]\n",
    "\n",
    "# Direct tab selection\n",
    "assert calculate_next_tab(\"db\", \"files\", tabs) == \"db\"\n",
    "assert calculate_next_tab(\"files\", \"db\", tabs) == \"files\"\n",
    "\n",
    "# Cycling forward\n",
    "assert calculate_next_tab(\"next\", \"db\", tabs) == \"files\"\n",
    "assert calculate_next_tab(\"next\", \"files\", tabs) == \"db\"\n",
    "\n",
    "# Cycling backward\n",
    "assert calculate_next_tab(\"prev\", \"db\", tabs) == \"files\"\n",
    "assert calculate_next_tab(\"prev\", \"files\", tabs) == \"db\"\n",
    "\n",
    "# Unknown current_tab defaults to index 0\n",
    "assert calculate_next_tab(\"next\", \"unknown\", tabs) == \"files\"\n",
    "\n",
    "print(\"calculate_next_tab tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-test-validate-path",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate_browse_path tests passed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "assert validate_browse_path(os.path.expanduser(\"~\")) == os.path.expanduser(\"~\")\n",
    "assert validate_browse_path(\"/nonexistent/path/xyz\") == os.path.expanduser(\"~\")\n",
    "print(\"validate_browse_path tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
